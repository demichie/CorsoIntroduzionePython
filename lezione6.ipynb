{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm7QidvWPt/GXleEO79kn1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demichie/CorsoIntroduzionePython/blob/main/lezione6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lezione 6: Analisi di Dati Tabulari con Pandas**\n",
        "\n",
        "Nelle lezioni precedenti abbiamo costruito una solida base: abbiamo imparato la sintassi di Python, come organizzare i dati in liste e dizionari, e come eseguire calcoli numerici efficienti con **NumPy**. Infine, con **Matplotlib**, abbiamo visto come trasformare i nostri array di numeri in visualizzazioni informative.\n",
        "\n",
        "Oggi facciamo il passo successivo e cruciale per ogni ricercatrice e ricercatore che deve analizzare dei dati: impariamo a lavorare con dati **tabulari**. I dati nel mondo reale raramente sono semplici griglie di numeri; più spesso, si presentano in formati strutturati come fogli di calcolo o tabelle, con righe che rappresentano osservazioni (es. un campione di roccia) e colonne che rappresentano variabili (es. SiO₂, MgO, Località), complete di etichette e tipi di dati misti (numeri, testo, date).\n",
        "\n",
        "Per gestire questo tipo di dati, useremo **Pandas**, la libreria più importante in Python per l'analisi e la manipolazione di dati tabulari.\n",
        "\n",
        "### **Obiettivi dettagliati della Lezione 6:**\n",
        "*   Comprendere il ruolo di **Pandas** e la sua struttura dati centrale: il **DataFrame**.\n",
        "*   Imparare a **leggere dati** da file esterni, in particolare file `.csv`, usando `pd.read_csv()`.\n",
        "*   Sviluppare un flusso di lavoro standard per **ispezionare** un DataFrame appena caricato (`.head()`, `.info()`, `.describe()`).\n",
        "*   **Pulire** i dati, a partire dalla standardizzazione dei nomi delle colonne.\n",
        "*   Imparare le tecniche fondamentali per **selezionare e filtrare** i dati: per colonna, per posizione/etichetta di riga (`.iloc`, `.loc`) e tramite condizioni (`masking booleano`).\n",
        "*   **Creare nuove colonne** basate su calcoli tra quelle esistenti."
      ],
      "metadata": {
        "id": "R3dMsjOsC5Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Perché Pandas? Oltre gli Array NumPy**\n",
        "\n",
        "Pandas è una libreria costruita sopra NumPy e ne sfrutta la potenza per i calcoli veloci. Tuttavia, aggiunge due strutture dati fondamentali che risolvono i limiti degli array \"nudi\":\n",
        "\n",
        "1.  **La `Series`**: Possiamo pensarla come una singola colonna di una tabella. È essenzialmente un array NumPy 1D a cui è associato un **indice** (una serie di etichette). Questo indice ci permette di accedere ai dati in modo più flessibile e significativo rispetto alla sola posizione numerica.\n",
        "\n",
        "2.  **Il `DataFrame`**: Questa è la struttura dati centrale di Pandas e sarà il nostro principale strumento di lavoro. Un DataFrame è una **tabella a 2 dimensioni**, simile a un foglio di calcolo o a una tabella di un database.\n",
        "\n",
        "    *   È composto da più `Series` (le colonne), ognuna con il proprio nome.\n",
        "    *   Le colonne possono avere tipi di dati diversi (es. una colonna di testo per i nomi, una di numeri per le elevazioni).\n",
        "    *   Condivide un unico **indice** per le righe, che permette di allineare i dati in modo coerente.\n",
        "\n",
        "In pratica, il DataFrame aggiunge un contesto ricco (etichette di riga e colonna, tipi di dati eterogenei) alla velocità di calcolo di NumPy."
      ],
      "metadata": {
        "id": "ZApzpOKrDIqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importiamo le librerie che useremo in questa lezione.\n",
        "# La convenzione standard è importare pandas con l'alias 'pd'.\n",
        "# Useremo anche NumPy, dato che Pandas è costruito su di esso.\n",
        "# Per questa lezione, useremo 'kagglehub' per scaricare i dati e 'os'\n",
        "# per interagire con il file system.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "print(\"Librerie importate con successo!\")"
      ],
      "metadata": {
        "id": "KjObMlNmDqjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 1: Caricare i Dati: File Locali e Risorse Online**\n",
        "\n",
        "Il primo passo di ogni analisi dati è importare i dati nel nostro ambiente di lavoro. Tipicamente, i dati si trovano in file (come `.csv` o fogli Excel) salvati sul nostro computer. In quel caso, passeremmo a Pandas il percorso locale del file.\n",
        "\n",
        "Tuttavia, per rendere questa lezione facilmente riproducibile per tutti e per lavorare con un dataset interessante e reale, scaricheremo i nostri dati direttamente da **Kaggle**.\n",
        "\n",
        "**Cos'è Kaggle?**\n",
        "[Kaggle](https://www.kaggle.com/) è una piattaforma online popolarissima per la data science. È un luogo dove si possono trovare migliaia di dataset pubblici, partecipare a competizioni di machine learning e condividere analisi. È una risorsa inestimabile per fare pratica.\n",
        "\n",
        "Per interagire con Kaggle direttamente dal nostro notebook, useremo la libreria `kagglehub`.\n",
        "\n",
        "**Il Nostro Dataset: Eruzioni Vulcaniche dal GVP**\n",
        "Il dataset che useremo è il catalogo delle eruzioni vulcaniche del **Global Volcanism Program (GVP)**, curato dalla Smithsonian Institution. Contiene un'enorme quantità di informazioni sui vulcani della Terra e la loro attività. Potete trovare la pagina web del dataset [qui](https://www.kaggle.com/datasets/smithsonian/volcanic-eruptions).\n",
        "\n",
        "Useremo `kagglehub` per scaricare questo dataset. La funzione si occuperà di scaricare i file e scompattarli in una cartella locale, pronta per essere esplorata."
      ],
      "metadata": {
        "id": "KB59rJ4HEQTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uno Strumento Essenziale: Interagire con il Sistema Operativo con la Libreria `os`**\n",
        "\n",
        "Una volta che `kagglehub` avrà scaricato i dati, questi si troveranno in una cartella sul nostro sistema. Per poterli leggere, dobbiamo prima capire **dove** sono e **quali file** contiene la cartella.\n",
        "\n",
        "Per fare questo, usiamo la libreria standard di Python `os`. Il suo nome sta per \"Operating System\" (Sistema Operativo), e ci fornisce gli strumenti per interagire con il file system in modo **indipendente dalla piattaforma** (funziona allo stesso modo su Windows, macOS e Linux).\n",
        "\n",
        "Ci concentreremo su due funzioni principali:\n",
        "\n",
        "1.  **`os.listdir(percorso)`**: Restituisce una **lista** con i nomi di tutti i file e le sottocartelle presenti in un dato `percorso`. È il nostro strumento per \"guardare dentro\" una cartella.\n",
        "\n",
        "2.  **`os.path.join(percorso1, percorso2, ...)`**: È il modo **corretto e sicuro** per costruire un percorso di file. Unisce le stringhe usando il separatore giusto per il sistema operativo in uso (`/` o `\\`), rendendo il nostro codice portabile."
      ],
      "metadata": {
        "id": "sjvcgIF0Eaq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Esempio 1: Esplorare una cartella di sistema ---\n",
        "\n",
        "# Definiamo il percorso di una cartella. In Colab, '/content/' è la cartella di lavoro principale.\n",
        "# Questa cartella di solito contiene una sottocartella 'sample_data'.\n",
        "path_to_explore = '/content/'\n",
        "\n",
        "print(f\"Esplorazione della cartella: '{path_to_explore}'\")\n",
        "\n",
        "try:\n",
        "    # Usiamo os.listdir per vedere cosa c'è dentro\n",
        "    content_list = os.listdir(path_to_explore)\n",
        "    print(\"Contenuto trovato:\")\n",
        "    for item in content_list:\n",
        "        print(f\"- {item}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"La cartella '{path_to_explore}' non esiste.\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "a3wmgXTpEnYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Esempio 2: Costruire un percorso in modo sicuro ---\n",
        "\n",
        "# Definiamo le parti di un percorso. Immaginiamo di voler accedere a un file\n",
        "# che si trova dentro la cartella 'sample_data' vista prima.\n",
        "folder_name = 'sample_data'\n",
        "file_name = 'granulometrie.csv' # Un file di esempio in Colab\n",
        "\n",
        "# Usiamo os.path.join per creare il percorso completo\n",
        "full_path = os.path.join(path_to_explore, folder_name, file_name)\n",
        "\n",
        "print(f\"Percorso costruito con os.path.join: '{full_path}'\")\n",
        "\n",
        "# Nota: os.path.join si occupa della compatibilità per noi. Se eseguissimo questo\n",
        "# su Windows, l'output userebbe il backslash '\\\\' come separatore."
      ],
      "metadata": {
        "id": "nQkoZ4uKFU_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Applicazione Pratica: Troviamo e Prepariamo i Nostri Dati**\n",
        "\n",
        "Ora applicheremo gli strumenti della libreria `os` che abbiamo appena visto per creare un flusso di lavoro di caricamento dati robusto.\n",
        "\n",
        "La nostra strategia sarà la seguente:\n",
        "\n",
        "1.  **Download:** Useremo `kagglehub.dataset_download()` per scaricare e scompattare il dataset in una cartella locale. Salveremo il percorso di questa cartella in una variabile.\n",
        "2.  **Esplorazione:** Useremo `os.listdir()` per ispezionare il contenuto di questa cartella e identificare i file `.csv` disponibili.\n",
        "3.  **Preparazione:** Successivamente, nelle celle che seguono, useremo `os.path.join()` per costruire il percorso completo del file che ci interessa e `pd.read_csv()` per caricarlo in un DataFrame.\n",
        "\n",
        "Questo approccio in più passaggi è un esempio di \"programmazione difensiva\": non diamo per scontato dove siano i file o come si chiamino, ma lo scopriamo in modo programmatico."
      ],
      "metadata": {
        "id": "j432aCcjTO7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Download del Dataset ---\n",
        "print(\"Download del dataset 'smithsonian/volcanic-eruptions' dal KaggleHub...\")\n",
        "dataset_path = kagglehub.dataset_download(\"smithsonian/volcanic-eruptions\")\n",
        "print(\"Download completato.\")\n",
        "print(f\"I file del dataset si trovano nella cartella: {dataset_path}\\n\")\n",
        "\n",
        "\n",
        "# --- 2. Esplorazione del Contenuto della Cartella ---\n",
        "# Usiamo os.listdir per vedere quali file sono stati scaricati e identificare\n",
        "# i file .csv che ci interessano.\n",
        "print(\"File trovati nella cartella del dataset:\")\n",
        "try:\n",
        "    available_files = os.listdir(dataset_path)\n",
        "    # Creiamo una lista contenente solo i file che terminano con .csv\n",
        "    csv_files = [file for file in available_files if file.endswith('.csv')]\n",
        "\n",
        "    for file_name in available_files:\n",
        "        print(f\"- {file_name}\")\n",
        "\n",
        "    if not csv_files:\n",
        "        print(\"\\nATTENZIONE: Nessun file .csv trovato nella cartella del dataset.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRORE: La cartella del dataset '{dataset_path}' non è stata trovata.\")\n",
        "    csv_files = [] # Resetta a lista vuota in caso di errore"
      ],
      "metadata": {
        "id": "TFNPrHJ9FeCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Caricare Dati con `pd.read_csv()`: Potenza e Flessibilità**\n",
        "\n",
        "Ora che abbiamo identificato i file `.csv` nel nostro dataset, è il momento di caricarli in un DataFrame. La funzione `pd.read_csv()` è lo strumento principale per importare dati tabulari in Pandas. Sebbene il nome suggerisca che funzioni solo con file \"CSV\" (Comma-Separated Values), in realtà è un parser di file di testo estremamente potente e configurabile.\n",
        "\n",
        "**Quali tipi di file possiamo leggere?**\n",
        "`pd.read_csv()` può gestire quasi ogni file di testo strutturato in colonne, a patto di specificare le opzioni corrette. Questo include file `.tsv` (separati da tab), file con separatori personalizzati (`;`, `|`), file senza intestazione, e molto altro.\n",
        "\n",
        "**Le Opzioni Più Comuni di `read_csv()`**\n",
        "Per gestire questa varietà di formati, `pd.read_csv()` accetta decine di argomenti opzionali. Vediamo i più importanti in una tabella riassuntiva.\n",
        "\n",
        "| Argomento          | Descrizione                                                                                                   | Esempio d'uso                                          |\n",
        "|--------------------|---------------------------------------------------------------------------------------------------------------|--------------------------------------------------------|\n",
        "| `filepath_or_buffer` | **(Obbligatorio)** Il percorso del file locale, un URL, o un oggetto file.                                       | `'data/mio_file.csv'` o `'http://.../data.csv'`      |\n",
        "| `sep` (o `delimiter`)| Il carattere usato per separare i valori. Di default è la virgola (`,`).                                        | `sep='\\t'` (per file .tsv) o `sep=';'`                   |\n",
        "| `header`           | Indica quale riga del file usare come intestazione. Di default è `0` (la prima riga).                           | `header=None` (se il file non ha intestazione)         |\n",
        "| `names`            | Una lista di nomi di colonna da usare, tipicamente con `header=None`.                                         | `names=['col1', 'col2']`                               |\n",
        "| `index_col`        | Indica quale colonna usare come indice del DataFrame.                                                          | `index_col=0` (la prima colonna) o `index_col='ID'`      |\n",
        "| `usecols`          | Una lista di nomi o indici di colonna per leggere solo un sottoinsieme delle colonne.                           | `usecols=['col1', 'col3']`                             |\n",
        "| `skiprows`         | Un numero intero per saltare le prime `n` righe del file (utile per saltare commenti).                         | `skiprows=5`                                           |\n",
        "| `nrows`            | Un numero intero per leggere solo le prime `n` righe di dati (ottimo per file molto grandi).                   | `nrows=1000`                                           |\n",
        "| `na_values`        | Una stringa o una lista di stringhe da riconoscere come valori mancanti (NaN).                                 | `na_values=['N/A', '-999']`                            |\n",
        "| `decimal`          | Il carattere da usare come separatore decimale (es. in Europa si usa la virgola).                               | `decimal=','`                                          |\n",
        "\n",
        "**Esempio pratico:**\n",
        "Se avessimo un file `dati.txt` separato da punto e virgola, senza header, e con la virgola come separatore decimale, lo caricheremmo così:\n",
        "\n",
        "```python\n",
        "# df_esempio = pd.read_csv(\n",
        "#     'dati.txt',\n",
        "#     sep=';',\n",
        "#     header=None,\n",
        "#     names=['temperatura', 'pressione'],\n",
        "#     decimal=','\n",
        "# )\n",
        "```\n",
        "\n",
        "Per la nostra lezione, i file `.csv` del GVP sono ben formattati, quindi l'uso base di `pd.read_csv()` sarà sufficiente."
      ],
      "metadata": {
        "id": "4gYPhcCWGG1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Caricamento del primo file CSV trovato ---\n",
        "\n",
        "# Inizializziamo il nostro DataFrame come vuoto.\n",
        "df = pd.DataFrame()\n",
        "file_loaded = \"\" # Una variabile per tenere traccia del nome del file caricato\n",
        "\n",
        "# La variabile 'csv_files' (la lista dei file CSV) è stata creata nella cella precedente.\n",
        "# Controlliamo se la lista contiene almeno un file.\n",
        "if csv_files:\n",
        "    # Selezioniamo il primo file CSV dalla lista. NESSUNA ASSUNZIONE SUL NOME.\n",
        "    file_to_load = csv_files[0]\n",
        "\n",
        "    # Costruiamo il percorso completo del file\n",
        "    file_path = os.path.join(dataset_path, file_to_load)\n",
        "\n",
        "    print(f\"Trovati file CSV. Caricamento del primo della lista: '{file_path}'\")\n",
        "\n",
        "    try:\n",
        "        # Usiamo pd.read_csv per caricare il file\n",
        "        df = pd.read_csv(file_path)\n",
        "        file_loaded = file_to_load # Salviamo il nome del file caricato\n",
        "        print(\"Caricamento completato con successo!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERRORE durante il caricamento del file: {e}\")\n",
        "        # 'df' rimarrà vuoto come inizializzato\n",
        "\n",
        "else:\n",
        "    print(\"\\nCaricamento saltato: nessun file .csv trovato nella cartella del dataset.\")"
      ],
      "metadata": {
        "id": "wWsfBm1EGa4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nota: Lavorare con Altri Formati - `pd.read_excel()`**\n",
        "\n",
        "Sebbene `read_csv()` sia la funzione più comune, nel lavoro di tutti i giorni vi capiterà spessissimo di avere dati in **fogli di calcolo Excel (`.xls` o `.xlsx`)**.\n",
        "\n",
        "Pandas gestisce questo formato in modo altrettanto semplice con la funzione `pd.read_excel()`.\n",
        "\n",
        "**Sintassi di base:**\n",
        "```python\n",
        "# df_excel = pd.read_excel('percorso/del/mio_file.xlsx')\n",
        "```\n",
        "\n",
        "La funzione `read_excel` è molto potente e accetta argomenti specifici per i file Excel, come:\n",
        "*   `sheet_name`: Per specificare quale foglio di lavoro leggere (per nome o per indice). Di default legge il primo. `sheet_name='Dati_Greggi'` o `sheet_name=1`.\n",
        "*   `skiprows`, `header`, `usecols`, ecc.: Molti degli argomenti che abbiamo visto per `read_csv` funzionano anche qui.\n",
        "\n",
        "**Requisiti di Installazione:**\n",
        "A differenza di `read_csv`, per leggere file Excel, Pandas ha bisogno di una libreria aggiuntiva (un \"motore\"). Le più comuni sono **`openpyxl`** (per file `.xlsx`) e **`xlrd`** (per i vecchi file `.xls`).\n",
        "\n",
        "Se provate a eseguire `pd.read_excel()` senza averle installate, Pandas vi darà un errore molto chiaro, suggerendovi il comando da eseguire per installarle, ad esempio:\n",
        "`pip install openpyxl`\n",
        "\n",
        "Per questa lezione continueremo a usare il nostro file `.csv`, ma è fondamentale sapere che Pandas è perfettamente equipaggiato per interagire direttamente con i vostri file Excel."
      ],
      "metadata": {
        "id": "yI5LJ6z1IWqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 2: Ispezione e Pulizia Iniziale del DataFrame**\n",
        "\n",
        "Abbiamo caricato i nostri dati in un DataFrame Pandas chiamato `df`. Ma cosa contiene esattamente? È stato caricato correttamente? Quante righe ha? Quali sono le colonne?\n",
        "\n",
        "Prima di iniziare qualsiasi analisi, il primo passo fondamentale è sempre **ispezionare** il DataFrame per capirne la struttura e il contenuto. Pandas ci offre una serie di comandi semplici e potenti per questa \"ricognizione\" iniziale.\n",
        "\n",
        "### **Controllo Preliminare: l'attributo `.empty`**\n",
        "\n",
        "Prima ancora di guardare i dati, è una buona pratica verificare se il caricamento ha avuto successo e se il DataFrame contiene effettivamente qualcosa. Potrebbe essere vuoto se il file di origine era vuoto o se si è verificato un errore che abbiamo gestito.\n",
        "\n",
        "Per fare questo controllo, usiamo l'attributo `.empty`.\n",
        "*   `df.empty` restituisce `True` se il DataFrame non ha righe.\n",
        "*   `df.empty` restituisce `False` se il DataFrame contiene almeno una riga.\n",
        "\n",
        "Useremo questo attributo per assicurarci di non provare a eseguire operazioni su un DataFrame vuoto.\n",
        "\n",
        "### **Prima Occhiata ai Dati: `.head()`**\n",
        "\n",
        "Una volta sicuri che il DataFrame non è vuoto, il primo comando da lanciare è quasi sempre `.head()`. Questo metodo ci mostra le **prime 5 righe** del DataFrame. È il modo più rapido per avere un'idea visiva di:\n",
        "*   I nomi delle colonne.\n",
        "*   Il tipo di dati in ogni colonna (numeri, testo, ecc.).\n",
        "*   La struttura generale della tabella.\n",
        "\n",
        "È possibile specificare un numero diverso di righe da visualizzare passandolo come argomento, ad esempio `df.head(10)` per vedere le prime 10 righe."
      ],
      "metadata": {
        "id": "A2NFzMTRObzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Controlliamo se il DataFrame non è vuoto prima di provare a ispezionarlo\n",
        "if not df.empty:\n",
        "    print(f\"Visualizzazione delle prime 5 righe del file '{file_loaded}':\")\n",
        "    # La funzione display() di Jupyter formatta l'output dei DataFrame in modo molto leggibile\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto, non c'è nulla da visualizzare.\")"
      ],
      "metadata": {
        "id": "1ri3XIFSOf66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ottenere un Riepilogo Tecnico e Statistico**\n",
        "\n",
        "Oltre a `.head()` per un'ispezione visiva, Pandas offre due metodi potentissimi per ottenere un riepilogo quantitativo del nostro DataFrame.\n",
        "\n",
        "#### **Riepilogo Tecnico: `.info()`**\n",
        "Il metodo `.info()` fornisce una sintesi concisa della struttura del DataFrame. È fondamentale per capire:\n",
        "*   Il numero totale di righe (Entries).\n",
        "*   L'elenco di tutte le colonne.\n",
        "*   Il numero di valori **non nulli** per ogni colonna. Questa è la prima e più importante indicazione della presenza di **dati mancanti** (`missing values`).\n",
        "*   Il tipo di dato (`Dtype`) di ogni colonna (es. `int64` per interi, `float64` per numeri decimali, `object` per stringhe o dati misti).\n",
        "*   L'utilizzo totale della memoria.\n",
        "\n",
        "#### **Riepilogo Statistico: `.describe()`**\n",
        "Il metodo `.describe()` calcola automaticamente le principali statistiche descrittive per tutte le **colonne numeriche**:\n",
        "*   `count`: Il numero di valori non nulli.\n",
        "*   `mean`: La media.\n",
        "*   `std`: La deviazione standard.\n",
        "*   `min`: Il valore minimo.\n",
        "*   `25%`, `50%`, `75%`: I percentili (il 50° percentile è la mediana).\n",
        "*   `max`: Il valore massimo.\n",
        "\n",
        "È un comando incredibilmente utile per avere una prima idea della distribuzione e della scala dei nostri dati numerici."
      ],
      "metadata": {
        "id": "w21Fr7SryGYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usiamo .info() per ottenere un riepilogo tecnico del nostro DataFrame\n",
        "if not df.empty:\n",
        "    print(\"Riepilogo tecnico del DataFrame:\")\n",
        "    df.info()\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")\n",
        "\n",
        "# PUNTO DI DISCUSSIONE:\n",
        "# Dall'output, cosa possiamo dedurre? Notiamo subito che le colonne 'Dominant Rock Type'\n",
        "# e 'Tectonic Setting' hanno meno valori non-nulli rispetto al totale delle righe.\n",
        "# Questo ci conferma la presenza di dati mancanti!"
      ],
      "metadata": {
        "id": "D5Z5_4kmyJbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usiamo .describe() per le statistiche delle colonne numeriche\n",
        "if not df.empty:\n",
        "    print(\"Riepilogo statistico delle colonne numeriche:\")\n",
        "    # display() formatta bene anche l'output di .describe()\n",
        "    display(df.describe())\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")\n",
        "\n",
        "# PUNTO DI DISCUSSIONE:\n",
        "# Qualche osservazione interessante?\n",
        "# - La colonna 'Number' sembra un ID e non ha molto significato statistico.\n",
        "# - 'Elevation (Meters)' varia da valori negativi (vulcani sottomarini) a molto alti.\n",
        "# - La media della latitudine è positiva, suggerendo più vulcani nell'emisfero nord nel dataset."
      ],
      "metadata": {
        "id": "jYOrJl7tyL5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pulizia dei Dati: Standardizzare i Nomi delle Colonne**\n",
        "\n",
        "Dall'ispezione con `.head()` e `.info()`, abbiamo notato che i nomi delle colonne nel nostro DataFrame non sono ideali per la programmazione: contengono spazi (es. `'Activity Evidence'`), parentesi (es. `'Elevation (Meters)'`) e un mix di lettere maiuscole e minuscole.\n",
        "\n",
        "Questi nomi \"scomodi\" possono causare problemi:\n",
        "*   Non possiamo usare la notazione ad attributo (es. `df.Activity Evidence` darebbe un errore di sintassi).\n",
        "*   Sono più lunghi da scrivere e più facili da sbagliare (`df['Elevation (Meters)']`).\n",
        "\n",
        "Una delle primissime fasi della pulizia dei dati (`data cleaning`) è quasi sempre la **standardizzazione dei nomi delle colonne**. Una convenzione molto comune, nota come \"snake_case\", prevede di rendere tutti i caratteri minuscoli e di sostituire gli spazi con un trattino basso (`_`).\n",
        "\n",
        "Pandas ci offre diversi modi per farlo. Vediamo un approccio in due passaggi.\n",
        "\n",
        "#### **Passaggio 1: Rinominare Colonne Specifiche con `.rename()`**\n",
        "\n",
        "Per modifiche mirate, il metodo `.rename()` è lo strumento perfetto. Accetta un argomento `columns` a cui passiamo un **dizionario Python**.\n",
        "*   Le **chiavi** del dizionario sono i nomi delle colonne attuali che vogliamo cambiare.\n",
        "*   I **valori** del dizionario sono i nuovi nomi che vogliamo assegnare.\n",
        "\n",
        "**L'argomento `inplace=True`**\n",
        "Per default, i metodi di manipolazione di Pandas restituiscono una **nuova copia** del DataFrame con le modifiche applicate, lasciando l'originale intatto. Se vogliamo modificare il nostro DataFrame \"sul posto\" (cioè direttamente, senza creare una copia), possiamo usare l'argomento `inplace=True`. È una scelta di convenienza, ma bisogna usarla con attenzione.\n",
        "\n",
        "```python\n",
        "# Sintassi di esempio\n",
        "# df.rename(columns={'Vecchio Nome': 'nuovo_nome'}, inplace=True)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "of1Y8FZHG1kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passaggio 1: Usare il metodo .rename() per correggere le colonne più complesse.\n",
        "# .rename() accetta un dizionario dove le chiavi sono i nomi attuali e i valori sono i nuovi nomi.\n",
        "\n",
        "if not df.empty:\n",
        "    print(\"Nomi delle colonne PRIMA della rinomina:\")\n",
        "    print(df.columns.tolist()) # .columns.tolist() ci dà una lista pulita dei nomi\n",
        "\n",
        "    df.rename(columns={\n",
        "        'Elevation (Meters)': 'elevation_meters',\n",
        "        'Activity Evidence': 'activity_evidence',\n",
        "        'Last Known Eruption': 'last_known_eruption',\n",
        "        'Dominant Rock Type': 'dominant_rock_type',\n",
        "        'Tectonic Setting': 'tectonic_setting'\n",
        "    }, inplace=True) # inplace=True modifica il DataFrame direttamente, senza bisogno di fare df = ...\n",
        "\n",
        "    print(\"\\nNomi delle colonne DOPO la prima rinomina:\")\n",
        "    print(df.columns.tolist())\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto, nessuna colonna da rinominare.\")"
      ],
      "metadata": {
        "id": "lSWAHMH2Het_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Passaggio 2: Applicare una Trasformazione a Tutti i Nomi**\n",
        "\n",
        "Per operazioni sistematiche su tutti i nomi (come renderli tutti minuscoli o sostituire tutti gli spazi), è inefficiente usare `.rename()`. Un approccio molto più potente è:\n",
        "1.  Ottenere la lista di tutti i nomi delle colonne con `df.columns`.\n",
        "2.  Usare una **list comprehension** per creare una nuova lista con i nomi trasformati (es. usando i metodi delle stringhe `.lower()` e `.replace()`).\n",
        "3.  Assegnare questa nuova lista direttamente a `df.columns`.\n",
        "\n",
        "Questo pattern è estremamente comune e potente per la pulizia dei dati.\n"
      ],
      "metadata": {
        "id": "XKUgyr7oHiNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passaggio 2: Rendiamo tutto minuscolo e sostituiamo gli spazi rimanenti.\n",
        "# Un modo potente e \"Pythonico\" per farlo è usare una list comprehension per\n",
        "# creare una nuova lista di nomi e assegnarla a df.columns.\n",
        "\n",
        "if not df.empty:\n",
        "    # Per ogni nome di colonna in df.columns, lo rendiamo minuscolo e sostituiamo ' ' con '_'\n",
        "    nuovi_nomi = [col.lower().replace(' ', '_') for col in df.columns]\n",
        "\n",
        "    # Assegniamo la nuova lista di nomi all'attributo .columns del DataFrame\n",
        "    df.columns = nuovi_nomi\n",
        "\n",
        "    print(\"Nomi delle colonne finali e standardizzati:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    # Verifichiamo il risultato finale con .head()\n",
        "    print(\"\\nDataFrame con i nuovi nomi di colonna:\")\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")"
      ],
      "metadata": {
        "id": "hhlAQJi6Hi-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Digressione: I Metodi delle Stringhe, i Nostri Alleati per la Pulizia dei Dati**\n",
        "\n",
        "Nella cella precedente, abbiamo usato `col.lower().replace(' ', '_')` per trasformare i nomi delle colonne. Questa \"catena\" di comandi è un esempio perfetto di come si usano i **metodi delle stringhe** in Python.\n",
        "\n",
        "Un metodo è una funzione che \"appartiene\" a un oggetto. Le stringhe in Python hanno decine di metodi incredibilmente utili per manipolare il testo. Questi sono fondamentali nel *data cleaning*, perché i dati testuali nel mondo reale sono spesso \"sporchi\": contengono spazi extra, maiuscole/minuscole inconsistenti, caratteri indesiderati, ecc.\n",
        "\n",
        "Ripassiamo e introduciamo alcuni dei più importanti:\n",
        "\n",
        "| Metodo                 | Descrizione                                                                              | Esempio d'uso                                            |\n",
        "|------------------------|------------------------------------------------------------------------------------------|----------------------------------------------------------|\n",
        "| `.lower()`             | Converte tutti i caratteri della stringa in minuscolo.                                     | `'Etna'.lower()` -> `'etna'`                             |\n",
        "| `.upper()`             | Converte tutti i caratteri della stringa in maiuscolo.                                     | `'Etna'.upper()` -> `'ETNA'`                             |\n",
        "| `.strip()`             | Rimuove gli spazi (o altri caratteri specificati) dall'**inizio e dalla fine** della stringa. | `'  Vesuvio  '.strip()` -> `'Vesuvio'`                  |\n",
        "| `.replace(vecchio, nuovo)` | Sostituisce tutte le occorrenze della sottostringa `vecchio` con `nuovo`.                 | `'Last Known Eruption'.replace(' ', '_')` -> `'Last_Known_Eruption'` |\n",
        "| `.split(separatore)`   | Divide la stringa in una **lista** di sottostringhe, usando il `separatore` come punto di divisione. | `'45.5,8.5'.split(',')` -> `['45.5', '8.5']`        |\n",
        "| `.startswith(testo)`   | Restituisce `True` se la stringa inizia con `testo`, altrimenti `False`.                    | `'Volcano_Etna'.startswith('Volcano')` -> `True`         |\n",
        "| `.endswith(testo)`     | Restituisce `True` se la stringa finisce con `testo`, altrimenti `False`.                    | `'data.csv'.endswith('.csv')` -> `True`                  |\n",
        "\n",
        "Questi metodi possono essere **concatenati**: l'output di un metodo diventa l'input del successivo, permettendo trasformazioni complesse in una sola riga, come abbiamo fatto per i nomi delle colonne."
      ],
      "metadata": {
        "id": "HILKY0r0JKoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Esercizio Pratico: Pulire una Stringa di Dati**\n",
        "\n",
        "Immaginiamo di aver ricevuto una riga di dati da un vecchio file di testo, formattata come una singola stringa. Il nostro compito è estrarre e pulire le informazioni.\n",
        "\n",
        "**Dato di partenza:**\n",
        "Una stringa che contiene: ID del campione, tipo di roccia e percentuale di SiO₂, separati da punto e virgola e con spazi disordinati.\n",
        "`riga_dati = \"  SAMP-001 ; Basalt ; SiO2: 50.25%  \"`\n",
        "\n",
        "**Compiti:**\n",
        "1.  **Pulizia Iniziale:** Usa `.strip()` per rimuovere gli spazi inutili all'inizio e alla fine della stringa `riga_dati`.\n",
        "2.  **Suddivisione:** Usa `.split(';')` sulla stringa pulita per ottenere una lista di tre elementi. Salva il risultato in una variabile `dati_lista`.\n",
        "3.  **Pulizia degli Elementi:** Ora, per ogni elemento nella `dati_lista`, applica di nuovo `.strip()` per rimuovere gli spazi attorno a ogni valore. (Suggerimento: puoi farlo con una list comprehension!).\n",
        "4.  **Estrazione del Valore Numerico:** Prendi l'ultimo elemento della lista (es. `'SiO2: 50.25%'`). Usa `.replace()` due volte per rimuovere prima `'SiO2: '` e poi `'%'`. Infine, converti la stringa risultante in un numero `float`.\n",
        "5.  **Stampa i risultati finali:** Stampa l'ID del campione pulito, il tipo di roccia (in minuscolo) e il valore numerico di SiO₂."
      ],
      "metadata": {
        "id": "FeDys1bCJOZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dato di partenza\n",
        "riga_dati = \"  SAMP-001 ; Basalt ; SiO2: 50.25%  \"\n",
        "\n",
        "# 1. Pulizia Iniziale\n",
        "# Scrivi qui il tuo codice\n",
        "\n",
        "\n",
        "# 2. Suddivisione in una lista\n",
        "# Scrivi qui il tuo codice\n",
        "\n",
        "\n",
        "# 3. Pulizia di ogni elemento nella lista\n",
        "# Scrivi qui il tuo codice\n",
        "\n",
        "\n",
        "# 4. Estrazione e conversione del valore di SiO2\n",
        "# Scrivi qui il tuo codice\n",
        "\n",
        "\n",
        "# 5. Stampa dei risultati finali\n",
        "# Scrivi qui il tuo codice (es. print(f\"ID: {id_campione}, Tipo: {tipo_roccia}, SiO2: {sio2_valore}\"))"
      ],
      "metadata": {
        "id": "bxAkoWStJSX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dato di partenza\n",
        "riga_dati = \"  SAMP-001 ; Basalt ; SiO2: 50.25%  \"\n"
      ],
      "metadata": {
        "id": "NV9k1a05JlL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Soluzione ---\n",
        "\n",
        "# 1. Pulizia Iniziale\n",
        "# Usiamo .strip() per rimuovere gli spazi bianchi all'inizio e alla fine.\n",
        "riga_pulita = riga_dati.strip()\n",
        "print(f\"1. Dopo .strip() iniziale: '{riga_pulita}'\")\n"
      ],
      "metadata": {
        "id": "uPpisLLeJ3wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Suddivisione in una lista\n",
        "# Usiamo .split(';') per dividere la stringa in base al punto e virgola.\n",
        "dati_lista = riga_pulita.split(';')\n",
        "print(f\"2. Dopo .split(';'): {dati_lista}\")\n"
      ],
      "metadata": {
        "id": "LeYE-FKCJ2Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Pulizia di ogni elemento nella lista\n",
        "# Notiamo che ogni elemento ha ancora spazi attorno. Usiamo una list comprehension\n",
        "# per applicare .strip() a ogni elemento della lista.\n",
        "dati_lista_pulita = [elemento.strip() for elemento in dati_lista]\n",
        "print(f\"3. Dopo la pulizia di ogni elemento: {dati_lista_pulita}\")\n"
      ],
      "metadata": {
        "id": "UP3JuPGmJ0Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Estrazione e conversione del valore di SiO2\n",
        "# Prendiamo l'ultimo elemento della lista, che è la stringa del SiO2.\n",
        "sio2_stringa = dati_lista_pulita[2]\n",
        "\n",
        "# Usiamo una catena di .replace() per rimuovere il testo non numerico.\n",
        "# Primo replace: rimuove 'SiO2: ' (nota lo spazio)\n",
        "sio2_val_str = sio2_stringa.replace('SiO2: ', '')\n",
        "# Secondo replace: rimuove il simbolo '%'\n",
        "sio2_val_str = sio2_val_str.replace('%', '')\n",
        "\n",
        "print(f\"4. Stringa SiO2 dopo le sostituzioni: '{sio2_val_str}'\")\n",
        "\n",
        "# Infine, convertiamo la stringa pulita in un numero float.\n",
        "sio2_valore = float(sio2_val_str)\n",
        "print(f\"   Valore SiO2 convertito in float: {sio2_valore}\")"
      ],
      "metadata": {
        "id": "YAcDZXAhJyfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Stampa dei risultati finali\n",
        "# Estraiamo gli altri valori dalla lista pulita e formattiamo l'output.\n",
        "id_campione = dati_lista_pulita[0]\n",
        "tipo_roccia = dati_lista_pulita[1].lower() # Lo mettiamo in minuscolo come da richiesta\n",
        "\n",
        "print(\"\\n--- Risultati Finali ---\")\n",
        "print(f\"ID Campione: {id_campione}\")\n",
        "print(f\"Tipo Roccia: {tipo_roccia}\")\n",
        "print(f\"Valore SiO2: {sio2_valore}\")\n",
        "print(f\"Tipo di dato del valore SiO2: {type(sio2_valore)}\")"
      ],
      "metadata": {
        "id": "_3cpgyM4Jup8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 3: Selezionare e Filtrare i Dati**\n",
        "\n",
        "Ora che il nostro DataFrame `df` ha nomi di colonna puliti e standardizzati, possiamo iniziare la fase di analisi vera e propria: la **selezione dei dati**. Raramente siamo interessati a tutto il dataset in una volta; più spesso, vogliamo isolare specifiche colonne o righe che soddisfano determinati criteri.\n",
        "\n",
        "### **Selezione di Colonne**\n",
        "\n",
        "Ci sono due modi principali per selezionare una o più colonne da un DataFrame.\n",
        "\n",
        "**1. Selezionare una Singola Colonna**\n",
        "Per selezionare una singola colonna, si usa una sintassi simile a quella dei dizionari Python, passando il nome della colonna come stringa tra parentesi quadre. Il risultato è un oggetto **Pandas Series**.\n",
        "\n",
        "```python\n",
        "# Sintassi: df['nome_colonna']\n",
        "```\n",
        "Pandas offre anche una scorciatoia, la \"notazione ad attributo\" (`df.nome_colonna`), ma funziona solo se il nome della colonna non contiene spazi o caratteri speciali. Ora che abbiamo pulito i nostri nomi, potremmo usarla, ma la notazione con le parentesi quadre è universalmente più sicura e raccomandata.\n",
        "\n",
        "**2. Selezionare Più Colonne**\n",
        "Per selezionare più colonne, passiamo una **lista di nomi di colonna** all'interno delle parentesi quadre. Il risultato è un nuovo **DataFrame** contenente solo le colonne specificate.\n",
        "\n",
        "**Attenzione alla sintassi:** la \"lista dentro le parentesi\" risulta in **doppie parentesi quadre** `[[...]]`. Questo è un errore comune per chi inizia.\n",
        "```python\n",
        "# Sintassi: df[['colonna_1', 'colonna_2']]\n",
        "```\n"
      ],
      "metadata": {
        "id": "3GksBXTDKLpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assicuriamoci che il DataFrame 'df' esista e non sia vuoto\n",
        "if not df.empty:\n",
        "\n",
        "    # --- 1. Selezionare una singola colonna ('country') ---\n",
        "    # Il risultato è una Series\n",
        "    countries = df['country']\n",
        "\n",
        "    print(\"--- Selezione della colonna 'country' (una Series) ---\")\n",
        "    display(countries.head())\n",
        "    print(f\"Tipo di oggetto restituito: {type(countries)}\\n\")\n",
        "\n",
        "    # --- 2. Selezionare più colonne ('name', 'type', 'elevation_meters') ---\n",
        "    # Il risultato è un nuovo DataFrame\n",
        "    subset_df = df[['name', 'type', 'elevation_meters']]\n",
        "\n",
        "    print(\"--- Selezione di più colonne (un nuovo DataFrame) ---\")\n",
        "    display(subset_df.head())\n",
        "    print(f\"Tipo di oggetto restituito: {type(subset_df)}\")\n",
        "\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto. Impossibile selezionare colonne.\")"
      ],
      "metadata": {
        "id": "D9cc4qbYKZ_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Digressione: Ispezione Visiva di una Colonna Numerica**\n",
        "\n",
        "Nella cella precedente abbiamo visto come estrarre una singola colonna (una `Series` Pandas). Quando la colonna contiene dati numerici, possiamo usare le competenze di **Matplotlib** che abbiamo già acquisito per farci subito un'idea della sua distribuzione.\n",
        "\n",
        "Uno dei primi passi nell'analisi esplorativa di una nuova variabile numerica è visualizzarne la distribuzione tramite un **istogramma**. Questo ci aiuta a capire la scala dei valori, la presenza di outlier e la forma generale dei dati.\n",
        "\n",
        "Applichiamo subito questa tecnica alla colonna delle elevazioni dei vulcani che abbiamo appena pulito."
      ],
      "metadata": {
        "id": "M-8xDCniLad2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assicuriamoci che il DataFrame 'df' esista e non sia vuoto\n",
        "if not df.empty and 'elevation_meters' in df.columns:\n",
        "\n",
        "    # --- 1. Selezionare la colonna di interesse ---\n",
        "    # Il risultato è una Pandas Series, che si comporta in modo molto simile a un array NumPy\n",
        "    # quando passata a funzioni come plt.hist().\n",
        "    elevations = df['elevation_meters']\n",
        "\n",
        "    # --- 2. Creare un istogramma con Matplotlib ---\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.hist(elevations, bins=50, edgecolor='k')\n",
        "\n",
        "    # --- 3. Personalizzare il grafico ---\n",
        "    plt.title(\"Distribuzione delle Elevazioni dei Vulcani nel Dataset\")\n",
        "    plt.xlabel(\"Elevazione (metri)\")\n",
        "    plt.ylabel(\"Frequenza (Numero di Vulcani)\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"DataFrame vuoto o colonna 'elevation_meters' non trovata.\")"
      ],
      "metadata": {
        "id": "fbjb1Lv2Lcpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analisi di Colonne Categoriche: `.value_counts()`**\n",
        "\n",
        "Abbiamo visto come l'istogramma sia perfetto per analizzare la distribuzione di dati numerici. Ma come possiamo ottenere un riepilogo rapido per le colonne che contengono **dati categorici** (testo), come la colonna `type` o `country`?\n",
        "\n",
        "Per questo, Pandas ci offre il metodo `.value_counts()`. Applicato a una `Series` (una colonna), questo metodo fa due cose:\n",
        "1.  Conta le occorrenze di ogni valore unico nella colonna.\n",
        "2.  Restituisce una nuova `Series` con i valori unici come indice e i loro conteggi come valori, ordinata dal più frequente al meno frequente.\n",
        "\n",
        "È uno degli strumenti più utili per l'analisi esplorativa dei dati."
      ],
      "metadata": {
        "id": "B39CE0voOm-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assicuriamoci che il DataFrame non sia vuoto\n",
        "if not df.empty:\n",
        "\n",
        "    # Usiamo .value_counts() per vedere quali sono i tipi di vulcano più comuni\n",
        "    print(\"Conteggio dei vulcani per tipo (`type`):\")\n",
        "    type_counts = df['type'].value_counts()\n",
        "\n",
        "    display(type_counts.head(10)) # Mostriamo i 10 più comuni\n",
        "\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")"
      ],
      "metadata": {
        "id": "i30tCRfxOqH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Selezione di Righe: `.loc` e `.iloc`**\n",
        "\n",
        "Oltre a selezionare colonne (selezione \"verticale\"), una delle operazioni più comuni è selezionare righe specifiche (selezione \"orizzontale\"). Pandas offre due metodi principali per questo, ed è fondamentale capirne la differenza:\n",
        "\n",
        "1.  **`.iloc` (Integer Location)**\n",
        "    *   Questo metodo seleziona le righe in base alla loro **posizione numerica intera**, partendo da 0.\n",
        "    *   Si comporta esattamente come l'indicizzazione delle liste Python o degli array NumPy.\n",
        "    *   È utile quando si vuole \"la prima riga\", \"la decima riga\", o un \"intervallo di righe dalla quinta alla decima\".\n",
        "    *   La sintassi per lo slicing (`start:stop`) con `.iloc` **esclude** l'elemento `stop`, proprio come in Python standard.\n",
        "\n",
        "2.  **`.loc` (Location)**\n",
        "    *   Questo metodo seleziona le righe in base alla loro **etichetta dell'indice** (`index`).\n",
        "    *   Di default, l'indice di un DataFrame è una sequenza di numeri interi (0, 1, 2, ...), quindi in un DataFrame appena caricato, `.loc[0]` e `.iloc[0]` spesso fanno la stessa cosa.\n",
        "    *   La sintassi per lo slicing (`start_label:stop_label`) con `.loc`, a differenza di `.iloc`, **include** l'elemento `stop_label`.\n",
        "\n",
        "**Rendere l'Indice Significativo: `.set_index()`**\n",
        "Il vero potere di `.loc` emerge quando l'indice non è solo una sequenza di numeri, ma contiene informazioni significative, come l'ID di un campione o, nel nostro caso, il nome di un vulcano.\n",
        "\n",
        "Per trasformare una delle nostre colonne in un indice, usiamo il metodo `.set_index('nome_colonna')`. Questa operazione:\n",
        "1.  Prende la colonna specificata.\n",
        "2.  La sposta dal corpo del DataFrame per usarla come etichette per le righe (l'indice).\n",
        "3.  Restituisce un **nuovo** DataFrame con questo nuovo indice.\n",
        "\n",
        "Una volta impostato un indice di questo tipo, possiamo usare `.loc` per selezionare le righe in modo molto più leggibile e intuitivo, usando i nomi stessi dei vulcani.\n",
        "\n",
        "**In sintesi:**\n",
        "*   **`.iloc` -> Posizione numerica (es. `df.iloc[5]`).**\n",
        "*   **`.loc`  -> Etichetta dell'indice (es. `df.loc['Vesuvius']`).**\n",
        "\n",
        "Vediamo entrambi in azione."
      ],
      "metadata": {
        "id": "RA4nvITCNE5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assicuriamoci che il DataFrame non sia vuoto\n",
        "if not df.empty:\n",
        "    print(\"--- Esempi con .iloc (selezione per posizione) ---\\n\")\n",
        "\n",
        "    # 1. Selezionare la prima riga (posizione 0)\n",
        "    # Il risultato è una Series, dove l'indice sono i nomi delle colonne.\n",
        "    prima_riga = df.iloc[0]\n",
        "    print(\"Prima riga del DataFrame (come Series):\")\n",
        "    display(prima_riga)\n",
        "\n",
        "    # 2. Selezionare l'ultima riga (posizione -1)\n",
        "    ultima_riga = df.iloc[-1]\n",
        "    print(\"\\nUltima riga del DataFrame:\")\n",
        "    display(ultima_riga)\n",
        "\n",
        "    # 3. Selezionare un intervallo di righe (dalla posizione 5 alla 10 esclusa)\n",
        "    # Il risultato è un nuovo DataFrame\n",
        "    righe_5_a_9 = df.iloc[5:10]\n",
        "    print(\"\\nRighe dalla posizione 5 alla 9:\")\n",
        "    display(righe_5_a_9)\n",
        "\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")"
      ],
      "metadata": {
        "id": "eKcoZE6QL_iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Per dimostrare la vera potenza di .loc, dobbiamo prima impostare un indice significativo.\n",
        "# Usiamo la colonna 'name' (il nome del vulcano) come nuovo indice del DataFrame.\n",
        "# Il metodo .set_index() crea un nuovo DataFrame con l'indice specificato.\n",
        "if not df.empty:\n",
        "    print(\"Imposto la colonna 'name' come nuovo indice del DataFrame...\")\n",
        "    df_indexed = df.set_index('name')\n",
        "    display(df_indexed.head())\n",
        "\n",
        "    print(\"\\n--- Esempi con .loc (selezione per etichetta) ---\\n\")\n",
        "\n",
        "    try:\n",
        "        # 1. Selezionare una singola riga usando l'etichetta dell'indice\n",
        "        vesuvius_data = df_indexed.loc['Vesuvius']\n",
        "        print(\"Dati per il vulcano 'Vesuvius':\")\n",
        "        display(vesuvius_data)\n",
        "\n",
        "        # 2. Selezionare più righe passando una lista di etichette\n",
        "        etna_stromboli = df_indexed.loc[['Etna', 'Stromboli']]\n",
        "        print(\"\\nDati per 'Etna' e 'Stromboli':\")\n",
        "        display(etna_stromboli)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"ERRORE: Una delle etichette non è stata trovata nell'indice. Dettagli: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Si è verificato un errore: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")"
      ],
      "metadata": {
        "id": "x6yr02TvNMvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Selezione Condizionale (Filtri Booleani)**\n",
        "\n",
        "Spesso non vogliamo selezionare righe in base alla loro posizione o a un'etichetta fissa, ma in base a una **condizione sui loro dati**. Ad esempio, \"tutti i vulcani più alti di 3000 metri\" o \"tutti i vulcani in Italia\".\n",
        "\n",
        "Questa operazione, nota come **selezione condizionale** o **filtraggio booleano**, è una delle tecniche più potenti di Pandas. La logica è identica al *masking booleano* che abbiamo già visto in NumPy.\n",
        "\n",
        "Il processo si articola in due passaggi:\n",
        "\n",
        "1.  **Creare la Condizione (la Maschera):**\n",
        "    Si scrive una condizione logica che viene applicata a una colonna (una `Series`). Pandas esegue il confronto elemento per elemento (in modo vettorizzato) e restituisce una nuova `Series` contenente solo valori booleani (`True` o `False`).\n",
        "    *   `True` dove la condizione è soddisfatta.\n",
        "    *   `False` dove la condizione non è soddisfatta.\n",
        "\n",
        "2.  **Applicare il Filtro:**\n",
        "    Si usa questa `Series` booleana all'interno delle parentesi quadre del DataFrame. Pandas restituirà un nuovo DataFrame contenente solo le **righe** in cui la maschera era `True`.\n",
        "\n",
        "**Combinare Più Condizioni**\n",
        "Per creare filtri più complessi, possiamo combinare più condizioni usando gli operatori logici:\n",
        "*   `&` per **AND** (entrambe le condizioni devono essere vere).\n",
        "*   `|` per **OR** (almeno una delle condizioni deve essere vera).\n",
        "*   `~` per **NOT** (inverte la condizione).\n",
        "\n",
        "**ATTENZIONE:** Quando si combinano più condizioni, ogni singola condizione **deve essere racchiusa tra parentesi `()`**. Questo è un requisito di sintassi di Pandas.\n",
        "`df[(condizione_1) & (condizione_2)]`"
      ],
      "metadata": {
        "id": "TLFldfNINeMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assicuriamoci che il DataFrame non sia vuoto\n",
        "if not df.empty:\n",
        "\n",
        "    # --- Esempio 1: Filtro Semplice ---\n",
        "    # Vogliamo selezionare tutti i vulcani che si trovano in Giappone.\n",
        "\n",
        "    # 1. Creiamo la condizione (la maschera booleana)\n",
        "    condizione_giappone = df['country'] == 'Japan'\n",
        "\n",
        "    print(\"Maschera booleana per i vulcani in Giappone (prime 10 righe):\")\n",
        "    display(condizione_giappone.head(10))\n",
        "\n",
        "    # 2. Applichiamo il filtro\n",
        "    vulcani_giapponesi = df[condizione_giappone]\n",
        "\n",
        "    print(\"\\nDataFrame filtrato: solo i vulcani in Giappone (prime 5 righe):\")\n",
        "    display(vulcani_giapponesi.head())\n",
        "\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")"
      ],
      "metadata": {
        "id": "OzsZNqmENjhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assicuriamoci che il DataFrame non sia vuoto\n",
        "if not df.empty:\n",
        "\n",
        "    # --- Esempio 2: Filtro Complesso (due condizioni) ---\n",
        "    # Vogliamo selezionare tutti gli Stratovulcani ('Stratovolcano')\n",
        "    # che hanno un'elevazione superiore a 3000 metri.\n",
        "\n",
        "    # 1. Definiamo le due condizioni separatamente\n",
        "    condizione_tipo = df['type'] == 'Stratovolcano'\n",
        "    condizione_elevazione = df['elevation_meters'] > 3000\n",
        "\n",
        "    # 2. Combiniamo le condizioni con l'operatore AND (&)\n",
        "    # NOTA LE PARENTESI OBBLIGATORIE attorno a ogni condizione!\n",
        "    stratovulcani_alti = df[ (condizione_tipo) & (condizione_elevazione) ]\n",
        "\n",
        "    print(\"Vulcani che sono 'Stratovolcano' E hanno elevazione > 3000 metri:\")\n",
        "\n",
        "    # Mostriamo solo alcune colonne per una visualizzazione più pulita\n",
        "    display(stratovulcani_alti[['name', 'country', 'type', 'elevation_meters']])\n",
        "\n",
        "else:\n",
        "    print(\"Il DataFrame è vuoto.\")"
      ],
      "metadata": {
        "id": "YBiYe3jyNmsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Esercizio Finale: Analisi dei Vulcani Potenzialmente Pericolosi**\n",
        "\n",
        "È il momento di mettere insieme tutto ciò che abbiamo imparato su Pandas (e di richiamare qualcosa da Matplotlib) per condurre un'analisi completa.\n",
        "\n",
        "**Scenario:**\n",
        "Vogliamo analizzare il catalogo dei vulcani per identificare gli **Stratovulcani** che hanno avuto un'**eruzione datata nell'Olocene**. Questi sono candidati interessanti per studi di pericolosità vulcanica.\n",
        "\n",
        "**Compiti da Svolgere:**\n",
        "\n",
        "1.  **Preparazione del DataFrame:**\n",
        "    *   Assicurati che il DataFrame `df` sia caricato e che i nomi delle colonne siano stati puliti (tutti minuscoli e con `_` al posto degli spazi). Se necessario, riesegui le celle precedenti.\n",
        "\n",
        "2.  **Filtraggio dei Vulcani:**\n",
        "    *   Crea un nuovo DataFrame chiamato `dangerous_strato` che contenga solo i vulcani che soddisfano **entrambe** le seguenti condizioni:\n",
        "        *   La colonna `type` deve essere `'Stratovolcano'`.\n",
        "        *   La colonna `activity_evidence` deve essere `'Eruption Dated'`.\n",
        "    *   Stampa il numero di vulcani trovati. **Suggerimento:** puoi usare `len(dangerous_strato)` o l'attributo `.shape`.\n",
        "\n",
        "3.  **Analisi Statistica:**\n",
        "    *   Usa il metodo `.describe()` sul DataFrame `dangerous_strato` per ottenere le statistiche principali (in particolare, guarda l'elevazione). Qual è l'elevazione massima tra questi vulcani?\n",
        "\n",
        "4.  **Analisi Geografica:**\n",
        "    *   Usa il metodo `.value_counts()` sulla colonna `country` del DataFrame `dangerous_strato` per scoprire quali sono i 5 paesi con il maggior numero di questi vulcani. **Suggerimento:** puoi concatenare `.head(5)` dopo `.value_counts()`.\n",
        "\n",
        "5.  **Visualizzazione (Integrazione con Matplotlib):**\n",
        "    *   Crea un **istogramma** delle elevazioni (`elevation_meters`) dei vulcani nel DataFrame `dangerous_strato`.\n",
        "    *   Personalizza il grafico con un titolo (\"Distribuzione delle Elevazioni degli Stratovulcani Attivi\"), etichette per gli assi e una griglia."
      ],
      "metadata": {
        "id": "vEtz6boUOvI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ESERCIZIO FINALE ---\n",
        "\n",
        "# 1. Preparazione del DataFrame\n",
        "# Assicuriamoci che il DataFrame 'df' esista e sia pulito.\n",
        "if 'df' in locals() and not df.empty:\n",
        "    print(\"DataFrame 'df' pronto per l'analisi.\")\n",
        "else:\n",
        "    print(\"ERRORE: DataFrame 'df' non trovato o vuoto. Esegui le celle precedenti.\")\n",
        "\n",
        "# 2. Filtraggio dei Vulcani\n",
        "# Scrivi qui il tuo codice per creare 'dangerous_strato' e stamparne la dimensione.\n",
        "\n",
        "\n",
        "# 3. Analisi Statistica\n",
        "# Scrivi qui il tuo codice per usare .describe() su 'dangerous_strato'.\n",
        "\n",
        "\n",
        "# 4. Analisi Geografica\n",
        "# Scrivi qui il tuo codice per trovare i top 5 paesi con .value_counts().\n",
        "\n",
        "\n",
        "# 5. Visualizzazione (Istogramma)\n",
        "# Assicurati di aver importato matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "# Scrivi qui il tuo codice per creare l'istogramma delle elevazioni."
      ],
      "metadata": {
        "id": "_8y3YhmjOyN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ESERCIZIO FINALE: SOLUZIONE ---\n",
        "\n",
        "# 1. Preparazione del DataFrame\n",
        "# Ci assicuriamo che il DataFrame 'df' esista e non sia vuoto.\n",
        "if 'df' in locals() and not df.empty:\n",
        "    print(\"DataFrame 'df' pronto per l'analisi.\\n\")\n",
        "\n",
        "    # 2. Filtraggio dei Vulcani\n",
        "    print(\"--- 2. Filtraggio dei vulcani ---\")\n",
        "    # Definiamo le due condizioni booleane\n",
        "    condizione_tipo = df['type'] == 'Stratovolcano'\n",
        "    condizione_attivita = df['activity_evidence'] == 'Eruption Dated'\n",
        "\n",
        "    # Applichiamo entrambe le condizioni con l'operatore AND (&)\n",
        "    dangerous_strato = df[condizione_tipo & condizione_attivita]\n",
        "\n",
        "    print(f\"Trovati {len(dangerous_strato)} stratovulcani con eruzioni datate.\\n\")\n",
        "    # In alternativa, usando .shape: print(f\"Trovati {dangerous_strato.shape[0]} ...\")\n",
        "\n",
        "\n",
        "    # 3. Analisi Statistica\n",
        "    print(\"--- 3. Analisi statistica delle elevazioni ---\")\n",
        "    # Usiamo .describe() per ottenere un riepilogo statistico\n",
        "    # Selezioniamo solo la colonna 'elevation_meters' per un output più pulito\n",
        "    elevation_stats = dangerous_strato['elevation_meters'].describe()\n",
        "    display(elevation_stats)\n",
        "    print(f\"L'elevazione massima tra questi vulcani è: {elevation_stats['max']} metri.\\n\")\n",
        "\n",
        "\n",
        "    # 4. Analisi Geografica\n",
        "    print(\"--- 4. Analisi geografica (Top 5 Paesi) ---\")\n",
        "    # Usiamo .value_counts() sulla colonna 'country' e concateniamo .head(5)\n",
        "    top_5_countries = dangerous_strato['country'].value_counts().head(5)\n",
        "\n",
        "    print(\"I 5 paesi con il maggior numero di stratovulcani attivi in questo dataset sono:\")\n",
        "    display(top_5_countries)\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "    # 5. Visualizzazione (Istogramma)\n",
        "    print(\"--- 5. Visualizzazione della distribuzione delle elevazioni ---\")\n",
        "    # Assicuriamoci che matplotlib sia importato\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Selezioniamo la colonna delle elevazioni dal nostro DataFrame filtrato\n",
        "    elevations_to_plot = dangerous_strato['elevation_meters']\n",
        "\n",
        "    # Creiamo la figura e l'istogramma\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(elevations_to_plot, bins=30, edgecolor='black', alpha=0.7)\n",
        "\n",
        "    # Aggiungiamo le personalizzazioni\n",
        "    plt.title(\"Distribuzione delle Elevazioni degli Stratovulcani Attivi\")\n",
        "    plt.xlabel(\"Elevazione (metri)\")\n",
        "    plt.ylabel(\"Frequenza (Numero di Vulcani)\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Aggiungiamo una linea per la media\n",
        "    media_elevazione = elevation_stats['mean']\n",
        "    plt.axvline(media_elevazione, color='red', linestyle='--', linewidth=2, label=f'Media: {media_elevazione:.0f} m')\n",
        "    plt.legend()\n",
        "\n",
        "    # Mostriamo il grafico\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"ERRORE: DataFrame 'df' non trovato o vuoto. Esegui le celle precedenti per caricare e pulire i dati.\")"
      ],
      "metadata": {
        "id": "8SQqv4cJO87F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **(Opzionale) Esercizio per Casa: Analisi Geochimica di Rocce Ignee**\n",
        "\n",
        "Per fare ulteriore pratica con il flusso di lavoro che abbiamo visto oggi (Download -> Caricamento -> Filtro -> Visualizzazione), ecco un esercizio da svolgere in autonomia.\n",
        "\n",
        "L'obiettivo è scaricare un nuovo dataset geochimico da Kaggle e analizzare la distribuzione della Silice (SiO₂) per un tipo specifico di roccia.\n",
        "\n",
        "**Dataset da Utilizzare:**\n",
        "*   **Nome su Kaggle:** Geochemical Variations in Igneous Rocks - Mining\n",
        "*   **Identificativo per `kagglehub`:** `cristianminas/geochemical-variations-in-igneous-rocks-mining`\n",
        "\n",
        "**Compiti da Svolgere:**\n",
        "\n",
        "1.  **Download e Caricamento:**\n",
        "    *   In una nuova cella, usa `kagglehub.dataset_download()` con l'identificativo fornito per scaricare il dataset.\n",
        "    *   Usa `os.listdir()` per scoprire il nome del file `.csv` contenuto nel dataset.\n",
        "    *   Carica il file in un nuovo DataFrame Pandas (es. `df_igneous`).\n",
        "\n",
        "2.  **Ispezione e Pulizia:**\n",
        "    *   Usa `.head()` e `.info()` per ispezionare il nuovo DataFrame.\n",
        "    *   Pulisci i nomi delle colonne, rendendoli minuscoli e usando `_` al posto degli spazi o altri caratteri (come abbiamo fatto in lezione).\n",
        "\n",
        "3.  **Filtraggio:**\n",
        "    *   Crea un nuovo DataFrame chiamato `andesites` che contenga solo le righe dove il tipo di roccia (`rock name`) è `'Andesite'`. **Attenzione:** controlla il nome esatto della colonna e il valore testuale dopo l'ispezione! Potrebbe essere necessario usare `.str.contains('Andesite', case=False)` se la formattazione non è consistente.\n",
        "\n",
        "4.  **Selezione e Analisi:**\n",
        "    *   Dal DataFrame `andesites`, seleziona la colonna relativa alla SiO₂.\n",
        "    *   Quanti campioni di andesite ci sono nel dataset?\n",
        "    *   Qual è il contenuto medio di SiO₂ per queste andesiti? (Usa il metodo `.mean()`).\n",
        "\n",
        "5.  **Visualizzazione:**\n",
        "    *   Crea un **istogramma** della colonna per i soli campioni di andesite.\n",
        "    *   Personalizza il grafico con un titolo, etichette per gli assi (`SiO₂ (%)`, `Frequenza`) e una griglia.\n",
        "    *   (Bonus) Aggiungi una linea verticale (`axvline`) per indicare la media di SiO₂ che hai calcolato."
      ],
      "metadata": {
        "id": "ZE91eiJ0V-bz"
      }
    }
  ]
}